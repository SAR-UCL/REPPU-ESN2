{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'/home/ryuho/Documents/reddy/research/SMRAI/Data/REPPU/200/pbig5min.dat' #Ubuntu\n",
    "path = r'/home/sachin/research/data/REPPU/pbig5min.dat' #Server\n",
    "\n",
    "#read the REPPU data\n",
    "with open (path) as f:\n",
    "    rectype = np.dtype(np.float32)\n",
    "    reppu_data = np.fromfile(f, rectype) #size = 109,900,800\n",
    "\n",
    "reppu_data = reppu_data.reshape(-1,30,80)\n",
    "reppu_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read MHD dates and expand-out the date ranges\n",
    "mhd_data = pd.read_csv('mhd_dates.csv')\n",
    "expanded_dt = pd.concat([pd.Series(pd.date_range(start, end)) \n",
    "    for start, end in zip(mhd_data['start'], mhd_data['end'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reshaped = reppu_data.reshape(len(expanded_dt), 288, 30, 80) \n",
    "\n",
    "# Define coordinates\n",
    "time = np.arange(288)\n",
    "lat = np.linspace(53.1, 89.7, 30) #30 intervals between 53.1째 to 89.7째\n",
    "lon = np.linspace(1.6, 357.6, 80) #80 intervals between 1.6째 to 357.6째\n",
    "\n",
    "# Create 'dt' variable combining dates and five-minute intervals\n",
    "dt = []\n",
    "for day in expanded_dt:\n",
    "    for t in time:\n",
    "        dt.append(day + pd.Timedelta(minutes=t*5))\n",
    "dt = np.array(dt) #convert from list to numpy array\n",
    "\n",
    "# Create xarray Dataset\n",
    "ds = xr.Dataset({'potential': (['dt', 'lat', 'lon'], data_reshaped.reshape(-1, 30, 80))},\n",
    "coords={'dt': dt, 'lat': lat, 'lon': lon})\n",
    "\n",
    "# Add potential and units\n",
    "ds['potential'].attrs['units'] = 'kV'\n",
    "ds['potential'] = ds['potential'] * 1e-3 # Convert to kV\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_df = pd.read_csv('omni_mhd_5min.csv')\n",
    "#omni_df = pd.read_csv(omni_mhd_path+'omni_mhd_5min.csv')\n",
    "omni_df.set_index('dt', inplace=True) #set the datetime as the index\n",
    "omni_df = omni_df.ffill().bfill()\n",
    "omni_df = omni_df.dropna() #drop any remaining NaNs\n",
    "omni_df\n",
    "\n",
    "omni_ds = xr.Dataset(omni_df)\n",
    "omni_ds['dt'] = pd.to_datetime(omni_ds['dt']) #convert the index to datetime\n",
    "\n",
    "#merge OMNI with REPPU data\n",
    "reppu_omni_ds = ds.merge(omni_ds, join='inner')\n",
    "\n",
    "#select date range\n",
    "reppu_omni_ds = reppu_omni_ds.sortby('dt')\n",
    "#reppu_omni_ds = reppu_omni_ds.sel(dt=slice('2022-06-12', '2022-07-31'))\n",
    "reppu_omni_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slice = slice(0, 11520) #40days * 288 = 11520\n",
    "test_slice = slice(11520, None) #10 days * 288 = 2880 \n",
    "\n",
    "# Define the slice ranges for train and test data\n",
    "#train_slice = slice(0, 36576) #36576 / 24 / 12 = 127 days = 80% of the data\n",
    "t#est_slice = slice(36576, None) # 9216 / 24 / 12 = 32 days = 20% of the data\n",
    "\n",
    "ds_train = reppu_omni_ds.isel(dt=train_slice)\n",
    "ds_test = reppu_omni_ds.isel(dt=test_slice)\n",
    "\n",
    "X_train = ds_train.drop_vars('potential').to_array().values.T\n",
    "y_train = ds_train['potential'].values\n",
    "y_train = y_train.reshape(-1, 30*80)\n",
    "#y_train = np.mean(y_train, axis=1)\n",
    "\n",
    "X_test = ds_test.drop_vars('potential').to_array().values.T\n",
    "y_test = ds_test['potential'].values\n",
    "y_test = y_test.reshape(-1, 30*80)\n",
    "#y_test = np.mean(y_test, axis=1)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_normalized, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_normalized, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor.shape, y_train_tensor.shape, X_test_tensor.shape, y_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # Remove extra dimensions from output\n",
    "        out = self.fc(out[:, -1, :].squeeze())  # Squeeze the output\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 2\n",
    "\n",
    "# Instantiate the LSTM model with updated input_size\n",
    "input_size = 5\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 2400\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train_tensor), sequence_length):\n",
    "        # Extract a batch of sequences of length 12\n",
    "        inputs = X_train_tensor[i:i+sequence_length]\n",
    "        targets = y_train_tensor[i+sequence_length-1]\n",
    "        # Forward pass\n",
    "        outputs = model(inputs.unsqueeze(0)) # Add batch dimension\n",
    "        loss = criterion(outputs, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #if (epoch+1) % 10 == 0:\n",
    "    rmse = np.sqrt(loss.item())\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.2f}, RMSE: {rmse:.2f} V')\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    test_outputs = []\n",
    "    for i in range(0, len(X_test_tensor), sequence_length):\n",
    "        inputs = X_test_tensor[i:i+sequence_length]\n",
    "        output = model(inputs.unsqueeze(0))\n",
    "        test_outputs.append(output.item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smrai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
