{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#from torch.optim.lr_scheduler import StepLR\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xarray as xr\n",
    "#import joblib\n",
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "#import os\n",
    "#import shutil\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>pot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-10 00:00:00</td>\n",
       "      <td>5484.762695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-10 00:05:00</td>\n",
       "      <td>5247.855957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-10 00:10:00</td>\n",
       "      <td>5592.299805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-10 00:15:00</td>\n",
       "      <td>5834.336914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-10 00:20:00</td>\n",
       "      <td>5604.553711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45787</th>\n",
       "      <td>2022-08-19 23:35:00</td>\n",
       "      <td>-12768.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45788</th>\n",
       "      <td>2022-08-19 23:40:00</td>\n",
       "      <td>-13011.533203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45789</th>\n",
       "      <td>2022-08-19 23:45:00</td>\n",
       "      <td>-12235.481445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45790</th>\n",
       "      <td>2022-08-19 23:50:00</td>\n",
       "      <td>-9142.743164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45791</th>\n",
       "      <td>2022-08-19 23:55:00</td>\n",
       "      <td>-8919.089844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45792 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dt           pot\n",
       "0     2021-05-10 00:00:00   5484.762695\n",
       "1     2021-05-10 00:05:00   5247.855957\n",
       "2     2021-05-10 00:10:00   5592.299805\n",
       "3     2021-05-10 00:15:00   5834.336914\n",
       "4     2021-05-10 00:20:00   5604.553711\n",
       "...                   ...           ...\n",
       "45787 2022-08-19 23:35:00 -12768.093750\n",
       "45788 2022-08-19 23:40:00 -13011.533203\n",
       "45789 2022-08-19 23:45:00 -12235.481445\n",
       "45790 2022-08-19 23:50:00  -9142.743164\n",
       "45791 2022-08-19 23:55:00  -8919.089844\n",
       "\n",
       "[45792 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_reppu_data():\n",
    "    #path = r'/home/ryuho/Documents/reddy/research/SMRAI/Data/REPPU/200/pbig5min.dat' #Ubuntu\n",
    "    path = r'/home/sachin/Documents/NIPR/Research/Data/REPPU/pbig5min.dat' #Server\n",
    "\n",
    "    #read the REPPU data\n",
    "    with open (path) as f:\n",
    "        rectype = np.dtype(np.float32)\n",
    "        reppu_data = np.fromfile(f, rectype) #size = 109,900,800\n",
    "\n",
    "    reppu_data = reppu_data.reshape(-1,30,80)\n",
    "    reppu_data = reppu_data.mean(axis=1).mean(axis=1) #integrate over the 30x80 grid\n",
    "\n",
    "    #load MHD dates to match with REPPU data\n",
    "    mhd_data = pd.read_csv('mhd_dates.csv')\n",
    "    expanded_dt = pd.concat([pd.Series(pd.date_range(start, end)) \n",
    "        for start, end in zip(mhd_data['start'], mhd_data['end'])])\n",
    "    \n",
    "    time = np.arange(288)\n",
    "    dt = []\n",
    "    for day in expanded_dt:\n",
    "        for t in time:\n",
    "            dt.append(day + pd.Timedelta(minutes=t*5))\n",
    "    dt = np.array(dt) #convert from list to numpy array\n",
    "    df = pd.DataFrame(reppu_data, index=dt)\n",
    "    df = df.rename(columns={0:'pot'})\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index':'dt'}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "reppu_df = process_reppu_data()\n",
    "reppu_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5395/1113075550.py:5: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  omni_df = omni_df.interpolate()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>pot</th>\n",
       "      <th>BY_GSE</th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>flow_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>tilt_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-10 00:00:00</td>\n",
       "      <td>5.484763</td>\n",
       "      <td>4.720</td>\n",
       "      <td>6.240</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.1100</td>\n",
       "      <td>0.253032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-10 00:05:00</td>\n",
       "      <td>5.247856</td>\n",
       "      <td>4.350</td>\n",
       "      <td>6.550</td>\n",
       "      <td>344.0</td>\n",
       "      <td>11.4400</td>\n",
       "      <td>0.249749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-10 00:10:00</td>\n",
       "      <td>5.592300</td>\n",
       "      <td>4.610</td>\n",
       "      <td>6.560</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.6500</td>\n",
       "      <td>0.246494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-10 00:15:00</td>\n",
       "      <td>5.834337</td>\n",
       "      <td>4.650</td>\n",
       "      <td>6.890</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.6300</td>\n",
       "      <td>0.243269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-10 00:20:00</td>\n",
       "      <td>5.604554</td>\n",
       "      <td>4.880</td>\n",
       "      <td>7.340</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.4700</td>\n",
       "      <td>0.240075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45787</th>\n",
       "      <td>2022-08-19 23:35:00</td>\n",
       "      <td>-12.768094</td>\n",
       "      <td>-2.715</td>\n",
       "      <td>-4.450</td>\n",
       "      <td>653.5</td>\n",
       "      <td>6.3925</td>\n",
       "      <td>0.187198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45788</th>\n",
       "      <td>2022-08-19 23:40:00</td>\n",
       "      <td>-13.011534</td>\n",
       "      <td>-2.490</td>\n",
       "      <td>-4.470</td>\n",
       "      <td>655.0</td>\n",
       "      <td>6.2200</td>\n",
       "      <td>0.183724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45789</th>\n",
       "      <td>2022-08-19 23:45:00</td>\n",
       "      <td>-12.235482</td>\n",
       "      <td>-2.265</td>\n",
       "      <td>-4.555</td>\n",
       "      <td>654.0</td>\n",
       "      <td>5.9050</td>\n",
       "      <td>0.180298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45790</th>\n",
       "      <td>2022-08-19 23:50:00</td>\n",
       "      <td>-9.142744</td>\n",
       "      <td>-2.040</td>\n",
       "      <td>-4.640</td>\n",
       "      <td>653.0</td>\n",
       "      <td>5.5900</td>\n",
       "      <td>0.176873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45791</th>\n",
       "      <td>2022-08-19 23:55:00</td>\n",
       "      <td>-8.919090</td>\n",
       "      <td>-1.920</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>658.0</td>\n",
       "      <td>5.3400</td>\n",
       "      <td>0.173477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45792 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dt        pot  BY_GSE  BZ_GSE  flow_speed  \\\n",
       "0     2021-05-10 00:00:00   5.484763   4.720   6.240       344.0   \n",
       "1     2021-05-10 00:05:00   5.247856   4.350   6.550       344.0   \n",
       "2     2021-05-10 00:10:00   5.592300   4.610   6.560       345.0   \n",
       "3     2021-05-10 00:15:00   5.834337   4.650   6.890       344.0   \n",
       "4     2021-05-10 00:20:00   5.604554   4.880   7.340       345.0   \n",
       "...                   ...        ...     ...     ...         ...   \n",
       "45787 2022-08-19 23:35:00 -12.768094  -2.715  -4.450       653.5   \n",
       "45788 2022-08-19 23:40:00 -13.011534  -2.490  -4.470       655.0   \n",
       "45789 2022-08-19 23:45:00 -12.235482  -2.265  -4.555       654.0   \n",
       "45790 2022-08-19 23:50:00  -9.142744  -2.040  -4.640       653.0   \n",
       "45791 2022-08-19 23:55:00  -8.919090  -1.920  -4.500       658.0   \n",
       "\n",
       "       proton_density  tilt_angle  \n",
       "0             12.1100    0.253032  \n",
       "1             11.4400    0.249749  \n",
       "2             12.6500    0.246494  \n",
       "3             12.6300    0.243269  \n",
       "4             12.4700    0.240075  \n",
       "...               ...         ...  \n",
       "45787          6.3925    0.187198  \n",
       "45788          6.2200    0.183724  \n",
       "45789          5.9050    0.180298  \n",
       "45790          5.5900    0.176873  \n",
       "45791          5.3400    0.173477  \n",
       "\n",
       "[45792 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_omni_and_merge(reppu_df):\n",
    "    reppu_df = reppu_df.copy()\n",
    "    \n",
    "    omni_df = pd.read_csv('omni_mhd_5min.csv')\n",
    "    omni_df = omni_df.interpolate()\n",
    "    #omni_df = omni_df.ffill().bfill() #interpolate missing values\n",
    "    #omni_df = omni_df.dropna() \n",
    "    omni_df['dt'] = pd.to_datetime(omni_df['dt'])\n",
    "\n",
    "    #merge the REPPU and OMNI data\n",
    "    df = pd.merge(reppu_df, omni_df, on='dt', how='outer')\n",
    "    #df = df[(df['dt'] >= '2021-12-01') & (df['dt'] <= '2022-01-24')]\n",
    "    #df = df[(df['dt'] >= '2021-12-01') & (df['dt'] <= '2021-12-02')]\n",
    "    #df = df[(df['dt'] >= '2021-05-10') & (df['dt'] <= '2021-05-15')] #Kp 7 storm\n",
    "    df['pot'] = df['pot'] * 1e-3\n",
    "    #interpolate\n",
    "    df = df.interpolate()\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "df = process_omni_and_merge(reppu_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pot</th>\n",
       "      <th>BY_GSE</th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>flow_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>tilt_angle</th>\n",
       "      <th>BY_GSE(t-1)</th>\n",
       "      <th>BZ_GSE(t-1)</th>\n",
       "      <th>flow_speed(t-1)</th>\n",
       "      <th>proton_density(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>BY_GSE(t-5)</th>\n",
       "      <th>BZ_GSE(t-5)</th>\n",
       "      <th>flow_speed(t-5)</th>\n",
       "      <th>proton_density(t-5)</th>\n",
       "      <th>tilt_angle(t-5)</th>\n",
       "      <th>BY_GSE(t-6)</th>\n",
       "      <th>BZ_GSE(t-6)</th>\n",
       "      <th>flow_speed(t-6)</th>\n",
       "      <th>proton_density(t-6)</th>\n",
       "      <th>tilt_angle(t-6)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-10 00:30:00</th>\n",
       "      <td>5.467443</td>\n",
       "      <td>4.620</td>\n",
       "      <td>8.020</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.2600</td>\n",
       "      <td>0.233785</td>\n",
       "      <td>4.970</td>\n",
       "      <td>7.680</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.2100</td>\n",
       "      <td>...</td>\n",
       "      <td>4.350</td>\n",
       "      <td>6.550</td>\n",
       "      <td>344.0</td>\n",
       "      <td>11.4400</td>\n",
       "      <td>0.249749</td>\n",
       "      <td>4.720</td>\n",
       "      <td>6.240</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.1100</td>\n",
       "      <td>0.253032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-10 00:35:00</th>\n",
       "      <td>4.203517</td>\n",
       "      <td>4.260</td>\n",
       "      <td>8.380</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.6500</td>\n",
       "      <td>0.230692</td>\n",
       "      <td>4.620</td>\n",
       "      <td>8.020</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.2600</td>\n",
       "      <td>...</td>\n",
       "      <td>4.610</td>\n",
       "      <td>6.560</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.6500</td>\n",
       "      <td>0.246494</td>\n",
       "      <td>4.350</td>\n",
       "      <td>6.550</td>\n",
       "      <td>344.0</td>\n",
       "      <td>11.4400</td>\n",
       "      <td>0.249749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-10 00:40:00</th>\n",
       "      <td>3.692068</td>\n",
       "      <td>3.280</td>\n",
       "      <td>8.890</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.1200</td>\n",
       "      <td>0.227636</td>\n",
       "      <td>4.260</td>\n",
       "      <td>8.380</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.6500</td>\n",
       "      <td>...</td>\n",
       "      <td>4.650</td>\n",
       "      <td>6.890</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.6300</td>\n",
       "      <td>0.243269</td>\n",
       "      <td>4.610</td>\n",
       "      <td>6.560</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.6500</td>\n",
       "      <td>0.246494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-10 00:45:00</th>\n",
       "      <td>2.930368</td>\n",
       "      <td>6.480</td>\n",
       "      <td>5.390</td>\n",
       "      <td>345.0</td>\n",
       "      <td>13.9800</td>\n",
       "      <td>0.224618</td>\n",
       "      <td>3.280</td>\n",
       "      <td>8.890</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.1200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.880</td>\n",
       "      <td>7.340</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.4700</td>\n",
       "      <td>0.240075</td>\n",
       "      <td>4.650</td>\n",
       "      <td>6.890</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.6300</td>\n",
       "      <td>0.243269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-10 00:50:00</th>\n",
       "      <td>2.470604</td>\n",
       "      <td>6.850</td>\n",
       "      <td>5.850</td>\n",
       "      <td>345.0</td>\n",
       "      <td>13.9900</td>\n",
       "      <td>0.221639</td>\n",
       "      <td>6.480</td>\n",
       "      <td>5.390</td>\n",
       "      <td>345.0</td>\n",
       "      <td>13.9800</td>\n",
       "      <td>...</td>\n",
       "      <td>4.970</td>\n",
       "      <td>7.680</td>\n",
       "      <td>344.0</td>\n",
       "      <td>12.2100</td>\n",
       "      <td>0.236913</td>\n",
       "      <td>4.880</td>\n",
       "      <td>7.340</td>\n",
       "      <td>345.0</td>\n",
       "      <td>12.4700</td>\n",
       "      <td>0.240075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-19 23:35:00</th>\n",
       "      <td>-12.768094</td>\n",
       "      <td>-2.715</td>\n",
       "      <td>-4.450</td>\n",
       "      <td>653.5</td>\n",
       "      <td>6.3925</td>\n",
       "      <td>0.187198</td>\n",
       "      <td>-2.940</td>\n",
       "      <td>-4.430</td>\n",
       "      <td>652.0</td>\n",
       "      <td>6.5650</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.480</td>\n",
       "      <td>-2.840</td>\n",
       "      <td>654.0</td>\n",
       "      <td>6.2100</td>\n",
       "      <td>0.204643</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>-1.660</td>\n",
       "      <td>642.0</td>\n",
       "      <td>6.5400</td>\n",
       "      <td>0.208167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-19 23:40:00</th>\n",
       "      <td>-13.011534</td>\n",
       "      <td>-2.490</td>\n",
       "      <td>-4.470</td>\n",
       "      <td>655.0</td>\n",
       "      <td>6.2200</td>\n",
       "      <td>0.183724</td>\n",
       "      <td>-2.715</td>\n",
       "      <td>-4.450</td>\n",
       "      <td>653.5</td>\n",
       "      <td>6.3925</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.935</td>\n",
       "      <td>-3.615</td>\n",
       "      <td>651.5</td>\n",
       "      <td>6.5600</td>\n",
       "      <td>0.201133</td>\n",
       "      <td>-4.480</td>\n",
       "      <td>-2.840</td>\n",
       "      <td>654.0</td>\n",
       "      <td>6.2100</td>\n",
       "      <td>0.204643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-19 23:45:00</th>\n",
       "      <td>-12.235482</td>\n",
       "      <td>-2.265</td>\n",
       "      <td>-4.555</td>\n",
       "      <td>654.0</td>\n",
       "      <td>5.9050</td>\n",
       "      <td>0.180298</td>\n",
       "      <td>-2.490</td>\n",
       "      <td>-4.470</td>\n",
       "      <td>655.0</td>\n",
       "      <td>6.2200</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.390</td>\n",
       "      <td>-4.390</td>\n",
       "      <td>649.0</td>\n",
       "      <td>6.9100</td>\n",
       "      <td>0.197622</td>\n",
       "      <td>-3.935</td>\n",
       "      <td>-3.615</td>\n",
       "      <td>651.5</td>\n",
       "      <td>6.5600</td>\n",
       "      <td>0.201133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-19 23:50:00</th>\n",
       "      <td>-9.142744</td>\n",
       "      <td>-2.040</td>\n",
       "      <td>-4.640</td>\n",
       "      <td>653.0</td>\n",
       "      <td>5.5900</td>\n",
       "      <td>0.176873</td>\n",
       "      <td>-2.265</td>\n",
       "      <td>-4.555</td>\n",
       "      <td>654.0</td>\n",
       "      <td>5.9050</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.165</td>\n",
       "      <td>-4.410</td>\n",
       "      <td>650.5</td>\n",
       "      <td>6.7375</td>\n",
       "      <td>0.194147</td>\n",
       "      <td>-3.390</td>\n",
       "      <td>-4.390</td>\n",
       "      <td>649.0</td>\n",
       "      <td>6.9100</td>\n",
       "      <td>0.197622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-19 23:55:00</th>\n",
       "      <td>-8.919090</td>\n",
       "      <td>-1.920</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>658.0</td>\n",
       "      <td>5.3400</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>-2.040</td>\n",
       "      <td>-4.640</td>\n",
       "      <td>653.0</td>\n",
       "      <td>5.5900</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.940</td>\n",
       "      <td>-4.430</td>\n",
       "      <td>652.0</td>\n",
       "      <td>6.5650</td>\n",
       "      <td>0.190673</td>\n",
       "      <td>-3.165</td>\n",
       "      <td>-4.410</td>\n",
       "      <td>650.5</td>\n",
       "      <td>6.7375</td>\n",
       "      <td>0.194147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45786 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pot  BY_GSE  BZ_GSE  flow_speed  proton_density  \\\n",
       "dt                                                                           \n",
       "2021-05-10 00:30:00   5.467443   4.620   8.020       344.0         12.2600   \n",
       "2021-05-10 00:35:00   4.203517   4.260   8.380       345.0         12.6500   \n",
       "2021-05-10 00:40:00   3.692068   3.280   8.890       344.0         12.1200   \n",
       "2021-05-10 00:45:00   2.930368   6.480   5.390       345.0         13.9800   \n",
       "2021-05-10 00:50:00   2.470604   6.850   5.850       345.0         13.9900   \n",
       "...                        ...     ...     ...         ...             ...   \n",
       "2022-08-19 23:35:00 -12.768094  -2.715  -4.450       653.5          6.3925   \n",
       "2022-08-19 23:40:00 -13.011534  -2.490  -4.470       655.0          6.2200   \n",
       "2022-08-19 23:45:00 -12.235482  -2.265  -4.555       654.0          5.9050   \n",
       "2022-08-19 23:50:00  -9.142744  -2.040  -4.640       653.0          5.5900   \n",
       "2022-08-19 23:55:00  -8.919090  -1.920  -4.500       658.0          5.3400   \n",
       "\n",
       "                     tilt_angle  BY_GSE(t-1)  BZ_GSE(t-1)  flow_speed(t-1)  \\\n",
       "dt                                                                           \n",
       "2021-05-10 00:30:00    0.233785        4.970        7.680            344.0   \n",
       "2021-05-10 00:35:00    0.230692        4.620        8.020            344.0   \n",
       "2021-05-10 00:40:00    0.227636        4.260        8.380            345.0   \n",
       "2021-05-10 00:45:00    0.224618        3.280        8.890            344.0   \n",
       "2021-05-10 00:50:00    0.221639        6.480        5.390            345.0   \n",
       "...                         ...          ...          ...              ...   \n",
       "2022-08-19 23:35:00    0.187198       -2.940       -4.430            652.0   \n",
       "2022-08-19 23:40:00    0.183724       -2.715       -4.450            653.5   \n",
       "2022-08-19 23:45:00    0.180298       -2.490       -4.470            655.0   \n",
       "2022-08-19 23:50:00    0.176873       -2.265       -4.555            654.0   \n",
       "2022-08-19 23:55:00    0.173477       -2.040       -4.640            653.0   \n",
       "\n",
       "                     proton_density(t-1)  ...  BY_GSE(t-5)  BZ_GSE(t-5)  \\\n",
       "dt                                        ...                             \n",
       "2021-05-10 00:30:00              12.2100  ...        4.350        6.550   \n",
       "2021-05-10 00:35:00              12.2600  ...        4.610        6.560   \n",
       "2021-05-10 00:40:00              12.6500  ...        4.650        6.890   \n",
       "2021-05-10 00:45:00              12.1200  ...        4.880        7.340   \n",
       "2021-05-10 00:50:00              13.9800  ...        4.970        7.680   \n",
       "...                                  ...  ...          ...          ...   \n",
       "2022-08-19 23:35:00               6.5650  ...       -4.480       -2.840   \n",
       "2022-08-19 23:40:00               6.3925  ...       -3.935       -3.615   \n",
       "2022-08-19 23:45:00               6.2200  ...       -3.390       -4.390   \n",
       "2022-08-19 23:50:00               5.9050  ...       -3.165       -4.410   \n",
       "2022-08-19 23:55:00               5.5900  ...       -2.940       -4.430   \n",
       "\n",
       "                     flow_speed(t-5)  proton_density(t-5)  tilt_angle(t-5)  \\\n",
       "dt                                                                           \n",
       "2021-05-10 00:30:00            344.0              11.4400         0.249749   \n",
       "2021-05-10 00:35:00            345.0              12.6500         0.246494   \n",
       "2021-05-10 00:40:00            344.0              12.6300         0.243269   \n",
       "2021-05-10 00:45:00            345.0              12.4700         0.240075   \n",
       "2021-05-10 00:50:00            344.0              12.2100         0.236913   \n",
       "...                              ...                  ...              ...   \n",
       "2022-08-19 23:35:00            654.0               6.2100         0.204643   \n",
       "2022-08-19 23:40:00            651.5               6.5600         0.201133   \n",
       "2022-08-19 23:45:00            649.0               6.9100         0.197622   \n",
       "2022-08-19 23:50:00            650.5               6.7375         0.194147   \n",
       "2022-08-19 23:55:00            652.0               6.5650         0.190673   \n",
       "\n",
       "                     BY_GSE(t-6)  BZ_GSE(t-6)  flow_speed(t-6)  \\\n",
       "dt                                                               \n",
       "2021-05-10 00:30:00        4.720        6.240            344.0   \n",
       "2021-05-10 00:35:00        4.350        6.550            344.0   \n",
       "2021-05-10 00:40:00        4.610        6.560            345.0   \n",
       "2021-05-10 00:45:00        4.650        6.890            344.0   \n",
       "2021-05-10 00:50:00        4.880        7.340            345.0   \n",
       "...                          ...          ...              ...   \n",
       "2022-08-19 23:35:00       -1.950       -1.660            642.0   \n",
       "2022-08-19 23:40:00       -4.480       -2.840            654.0   \n",
       "2022-08-19 23:45:00       -3.935       -3.615            651.5   \n",
       "2022-08-19 23:50:00       -3.390       -4.390            649.0   \n",
       "2022-08-19 23:55:00       -3.165       -4.410            650.5   \n",
       "\n",
       "                     proton_density(t-6)  tilt_angle(t-6)  \n",
       "dt                                                         \n",
       "2021-05-10 00:30:00              12.1100         0.253032  \n",
       "2021-05-10 00:35:00              11.4400         0.249749  \n",
       "2021-05-10 00:40:00              12.6500         0.246494  \n",
       "2021-05-10 00:45:00              12.6300         0.243269  \n",
       "2021-05-10 00:50:00              12.4700         0.240075  \n",
       "...                                  ...              ...  \n",
       "2022-08-19 23:35:00               6.5400         0.208167  \n",
       "2022-08-19 23:40:00               6.2100         0.204643  \n",
       "2022-08-19 23:45:00               6.5600         0.201133  \n",
       "2022-08-19 23:50:00               6.9100         0.197622  \n",
       "2022-08-19 23:55:00               6.7375         0.194147  \n",
       "\n",
       "[45786 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_feat_df(df, lookback, var):\n",
    "    df = df.copy()\n",
    "    #df = df[['dt',var]]\n",
    "\n",
    "    df.set_index('dt', inplace=True)\n",
    "    \n",
    "    for i in range(1, lookback+1):\n",
    "        #df[f'{var}(t-{i})'] = df[var].shift(i)\n",
    "        df[f'BY_GSE(t-{i})'] = df['BY_GSE'].shift(i)\n",
    "        df[f'BZ_GSE(t-{i})'] = df['BZ_GSE'].shift(i)\n",
    "        df[f'flow_speed(t-{i})'] = df['flow_speed'].shift(i)\n",
    "        df[f'proton_density(t-{i})'] = df['proton_density'].shift(i)\n",
    "        df[f'tilt_angle(t-{i})'] = df['tilt_angle'].shift(i)\n",
    "        \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "feat = 'pot'\n",
    "df = single_feat_df(df, 6, feat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_split_tensor(df):\n",
    "\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df.iloc[:, 0]\n",
    "\n",
    "    #scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    split_index = int(0.8*len(X))#80% train, 20% test\n",
    "\n",
    "    #split the data\n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[split_index:]\n",
    "\n",
    "    #add exta dim for torch reqs\n",
    "    X_train = X_train.reshape(-1, X.shape[1], 1)\n",
    "    X_test = X_test.reshape(-1, X.shape[1], 1)\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "    #convert to tensor\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor\n",
    "\n",
    "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = scale_split_tensor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36628, 35, 1]),\n",
       " torch.Size([9158, 35, 1]),\n",
       " torch.Size([36628, 1]),\n",
       " torch.Size([9158, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape, X_test_tensor.shape, y_train_tensor.shape, y_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 35, 1]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(1, 32, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = LSTM(1, 32, 2)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train(True)\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        output = model(x_batch)\n",
    "        loss = loss_function(output, y_batch)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 100 == 99:  # print every 100 batches\n",
    "            avg_loss_across_batches = running_loss / 100\n",
    "            print('Batch {0}, Loss: {1:.3f}'.format(batch_index+1,\n",
    "                                                    avg_loss_across_batches))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(x_batch)\n",
    "            loss = loss_function(output, y_batch)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(test_loader)\n",
    "    \n",
    "    print('Val Loss: {0:.3f}'.format(avg_loss_across_batches))\n",
    "    print('***************************************************')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Batch 100, Loss: 36.038\n",
      "Batch 200, Loss: 37.592\n",
      "Batch 300, Loss: 34.711\n",
      "Batch 400, Loss: 38.109\n",
      "Batch 500, Loss: 37.013\n",
      "Batch 600, Loss: 37.324\n",
      "Batch 700, Loss: 37.240\n",
      "Batch 800, Loss: 34.243\n",
      "Batch 900, Loss: 38.552\n",
      "Batch 1000, Loss: 32.568\n",
      "Batch 1100, Loss: 35.952\n",
      "Batch 1200, Loss: 35.913\n",
      "Batch 1300, Loss: 36.659\n",
      "Batch 1400, Loss: 35.858\n",
      "Batch 1500, Loss: 35.190\n",
      "Batch 1600, Loss: 35.247\n",
      "Batch 1700, Loss: 33.792\n",
      "Batch 1800, Loss: 35.256\n",
      "Batch 1900, Loss: 34.717\n",
      "Batch 2000, Loss: 33.932\n",
      "Batch 2100, Loss: 33.733\n",
      "Batch 2200, Loss: 38.064\n",
      "\n",
      "Val Loss: 42.234\n",
      "***************************************************\n",
      "\n",
      "Epoch: 2\n",
      "Batch 100, Loss: 36.299\n",
      "Batch 200, Loss: 33.953\n",
      "Batch 300, Loss: 35.675\n",
      "Batch 400, Loss: 33.741\n",
      "Batch 500, Loss: 35.782\n",
      "Batch 600, Loss: 35.420\n",
      "Batch 700, Loss: 34.036\n",
      "Batch 800, Loss: 32.206\n",
      "Batch 900, Loss: 36.728\n",
      "Batch 1000, Loss: 35.963\n",
      "Batch 1100, Loss: 33.015\n",
      "Batch 1200, Loss: 36.085\n",
      "Batch 1300, Loss: 32.744\n",
      "Batch 1400, Loss: 32.297\n",
      "Batch 1500, Loss: 32.080\n",
      "Batch 1600, Loss: 31.888\n",
      "Batch 1700, Loss: 31.663\n",
      "Batch 1800, Loss: 32.684\n",
      "Batch 1900, Loss: 33.182\n",
      "Batch 2000, Loss: 30.566\n",
      "Batch 2100, Loss: 31.513\n",
      "Batch 2200, Loss: 32.778\n",
      "\n",
      "Val Loss: 42.284\n",
      "***************************************************\n",
      "\n",
      "Epoch: 3\n",
      "Batch 100, Loss: 34.686\n",
      "Batch 200, Loss: 33.822\n",
      "Batch 300, Loss: 30.253\n",
      "Batch 400, Loss: 34.144\n",
      "Batch 500, Loss: 30.841\n",
      "Batch 600, Loss: 34.100\n",
      "Batch 700, Loss: 33.936\n",
      "Batch 800, Loss: 35.335\n",
      "Batch 900, Loss: 31.762\n",
      "Batch 1000, Loss: 33.460\n",
      "Batch 1100, Loss: 30.944\n",
      "Batch 1200, Loss: 31.485\n",
      "Batch 1300, Loss: 36.851\n",
      "Batch 1400, Loss: 31.158\n",
      "Batch 1500, Loss: 32.396\n",
      "Batch 1600, Loss: 32.228\n",
      "Batch 1700, Loss: 31.495\n",
      "Batch 1800, Loss: 32.069\n",
      "Batch 1900, Loss: 31.702\n",
      "Batch 2000, Loss: 32.097\n",
      "Batch 2100, Loss: 31.357\n",
      "Batch 2200, Loss: 29.966\n",
      "\n",
      "Val Loss: 40.494\n",
      "***************************************************\n",
      "\n",
      "Epoch: 4\n",
      "Batch 100, Loss: 33.531\n",
      "Batch 200, Loss: 32.271\n",
      "Batch 300, Loss: 30.614\n",
      "Batch 400, Loss: 34.080\n",
      "Batch 500, Loss: 31.748\n",
      "Batch 600, Loss: 33.457\n",
      "Batch 700, Loss: 29.698\n",
      "Batch 800, Loss: 31.089\n",
      "Batch 900, Loss: 31.497\n",
      "Batch 1000, Loss: 30.618\n",
      "Batch 1100, Loss: 30.599\n",
      "Batch 1200, Loss: 34.210\n",
      "Batch 1300, Loss: 31.721\n",
      "Batch 1400, Loss: 30.652\n",
      "Batch 1500, Loss: 31.023\n",
      "Batch 1600, Loss: 32.767\n",
      "Batch 1700, Loss: 31.277\n",
      "Batch 1800, Loss: 32.511\n",
      "Batch 1900, Loss: 33.828\n",
      "Batch 2000, Loss: 34.878\n",
      "Batch 2100, Loss: 34.696\n",
      "Batch 2200, Loss: 33.812\n",
      "\n",
      "Val Loss: 42.275\n",
      "***************************************************\n",
      "\n",
      "Epoch: 5\n",
      "Batch 100, Loss: 33.832\n",
      "Batch 200, Loss: 30.787\n",
      "Batch 300, Loss: 33.437\n",
      "Batch 400, Loss: 32.581\n",
      "Batch 500, Loss: 30.123\n",
      "Batch 600, Loss: 32.041\n",
      "Batch 700, Loss: 30.681\n",
      "Batch 800, Loss: 33.292\n",
      "Batch 900, Loss: 31.449\n",
      "Batch 1000, Loss: 32.643\n",
      "Batch 1100, Loss: 31.776\n",
      "Batch 1200, Loss: 33.062\n",
      "Batch 1300, Loss: 31.925\n",
      "Batch 1400, Loss: 29.935\n",
      "Batch 1500, Loss: 31.467\n",
      "Batch 1600, Loss: 32.132\n",
      "Batch 1700, Loss: 28.903\n",
      "Batch 1800, Loss: 29.818\n",
      "Batch 1900, Loss: 34.917\n",
      "Batch 2000, Loss: 30.689\n",
      "Batch 2100, Loss: 31.318\n",
      "Batch 2200, Loss: 32.124\n",
      "\n",
      "Val Loss: 40.926\n",
      "***************************************************\n",
      "\n",
      "Epoch: 6\n",
      "Batch 100, Loss: 31.567\n",
      "Batch 200, Loss: 31.273\n",
      "Batch 300, Loss: 29.947\n",
      "Batch 400, Loss: 29.684\n",
      "Batch 500, Loss: 31.308\n",
      "Batch 600, Loss: 34.390\n",
      "Batch 700, Loss: 32.108\n",
      "Batch 800, Loss: 29.794\n",
      "Batch 900, Loss: 30.488\n",
      "Batch 1000, Loss: 32.220\n",
      "Batch 1100, Loss: 32.028\n",
      "Batch 1200, Loss: 28.787\n",
      "Batch 1300, Loss: 31.410\n",
      "Batch 1400, Loss: 29.725\n",
      "Batch 1500, Loss: 29.560\n",
      "Batch 1600, Loss: 30.900\n",
      "Batch 1700, Loss: 32.041\n",
      "Batch 1800, Loss: 30.337\n",
      "Batch 1900, Loss: 29.899\n",
      "Batch 2000, Loss: 30.001\n",
      "Batch 2100, Loss: 30.517\n",
      "Batch 2200, Loss: 29.594\n",
      "\n",
      "Val Loss: 43.571\n",
      "***************************************************\n",
      "\n",
      "Epoch: 7\n",
      "Batch 100, Loss: 30.419\n",
      "Batch 200, Loss: 31.777\n",
      "Batch 300, Loss: 29.357\n",
      "Batch 400, Loss: 29.054\n",
      "Batch 500, Loss: 31.030\n",
      "Batch 600, Loss: 29.276\n",
      "Batch 700, Loss: 29.466\n",
      "Batch 800, Loss: 28.395\n",
      "Batch 900, Loss: 29.679\n",
      "Batch 1000, Loss: 29.255\n",
      "Batch 1100, Loss: 30.597\n",
      "Batch 1200, Loss: 29.811\n",
      "Batch 1300, Loss: 29.360\n",
      "Batch 1400, Loss: 30.976\n",
      "Batch 1500, Loss: 29.360\n",
      "Batch 1600, Loss: 30.289\n",
      "Batch 1700, Loss: 29.935\n",
      "Batch 1800, Loss: 31.409\n",
      "Batch 1900, Loss: 30.689\n",
      "Batch 2000, Loss: 28.666\n",
      "Batch 2100, Loss: 33.914\n",
      "Batch 2200, Loss: 29.781\n",
      "\n",
      "Val Loss: 44.353\n",
      "***************************************************\n",
      "\n",
      "Epoch: 8\n",
      "Batch 100, Loss: 31.905\n",
      "Batch 200, Loss: 28.455\n",
      "Batch 300, Loss: 30.550\n",
      "Batch 400, Loss: 28.672\n",
      "Batch 500, Loss: 31.981\n",
      "Batch 600, Loss: 31.279\n",
      "Batch 700, Loss: 31.676\n",
      "Batch 800, Loss: 29.410\n",
      "Batch 900, Loss: 29.256\n",
      "Batch 1000, Loss: 29.600\n",
      "Batch 1100, Loss: 30.622\n",
      "Batch 1200, Loss: 29.838\n",
      "Batch 1300, Loss: 29.108\n",
      "Batch 1400, Loss: 28.448\n",
      "Batch 1500, Loss: 27.044\n",
      "Batch 1600, Loss: 27.281\n",
      "Batch 1700, Loss: 31.016\n",
      "Batch 1800, Loss: 29.414\n",
      "Batch 1900, Loss: 28.787\n",
      "Batch 2000, Loss: 28.319\n",
      "Batch 2100, Loss: 28.291\n",
      "Batch 2200, Loss: 27.823\n",
      "\n",
      "Val Loss: 49.438\n",
      "***************************************************\n",
      "\n",
      "Epoch: 9\n",
      "Batch 100, Loss: 29.518\n",
      "Batch 200, Loss: 30.299\n",
      "Batch 300, Loss: 27.488\n",
      "Batch 400, Loss: 28.638\n",
      "Batch 500, Loss: 28.932\n",
      "Batch 600, Loss: 30.158\n",
      "Batch 700, Loss: 29.507\n",
      "Batch 800, Loss: 28.239\n",
      "Batch 900, Loss: 30.075\n",
      "Batch 1000, Loss: 27.897\n",
      "Batch 1100, Loss: 29.028\n",
      "Batch 1200, Loss: 31.746\n",
      "Batch 1300, Loss: 27.817\n",
      "Batch 1400, Loss: 31.396\n",
      "Batch 1500, Loss: 28.064\n",
      "Batch 1600, Loss: 27.685\n",
      "Batch 1700, Loss: 26.917\n",
      "Batch 1800, Loss: 29.015\n",
      "Batch 1900, Loss: 27.198\n",
      "Batch 2000, Loss: 29.089\n",
      "Batch 2100, Loss: 30.769\n",
      "Batch 2200, Loss: 29.742\n",
      "\n",
      "Val Loss: 47.161\n",
      "***************************************************\n",
      "\n",
      "Epoch: 10\n",
      "Batch 100, Loss: 30.419\n",
      "Batch 200, Loss: 28.673\n",
      "Batch 300, Loss: 28.853\n",
      "Batch 400, Loss: 27.781\n",
      "Batch 500, Loss: 27.593\n",
      "Batch 600, Loss: 29.777\n",
      "Batch 700, Loss: 27.543\n",
      "Batch 800, Loss: 26.800\n",
      "Batch 900, Loss: 28.189\n",
      "Batch 1000, Loss: 27.943\n",
      "Batch 1100, Loss: 29.189\n",
      "Batch 1200, Loss: 28.144\n",
      "Batch 1300, Loss: 30.977\n",
      "Batch 1400, Loss: 27.722\n",
      "Batch 1500, Loss: 29.941\n",
      "Batch 1600, Loss: 26.875\n",
      "Batch 1700, Loss: 31.000\n",
      "Batch 1800, Loss: 27.887\n",
      "Batch 1900, Loss: 29.924\n",
      "Batch 2000, Loss: 26.736\n",
      "Batch 2100, Loss: 27.543\n",
      "Batch 2200, Loss: 28.160\n",
      "\n",
      "Val Loss: 46.914\n",
      "***************************************************\n",
      "\n",
      "Epoch: 11\n",
      "Batch 100, Loss: 28.025\n",
      "Batch 200, Loss: 27.242\n",
      "Batch 300, Loss: 27.641\n",
      "Batch 400, Loss: 27.484\n",
      "Batch 500, Loss: 26.255\n",
      "Batch 600, Loss: 27.807\n",
      "Batch 700, Loss: 28.833\n",
      "Batch 800, Loss: 28.396\n",
      "Batch 900, Loss: 26.114\n",
      "Batch 1000, Loss: 29.666\n",
      "Batch 1100, Loss: 28.516\n",
      "Batch 1200, Loss: 27.314\n",
      "Batch 1300, Loss: 26.885\n",
      "Batch 1400, Loss: 25.863\n",
      "Batch 1500, Loss: 25.596\n",
      "Batch 1600, Loss: 28.806\n",
      "Batch 1700, Loss: 28.392\n",
      "Batch 1800, Loss: 28.905\n",
      "Batch 1900, Loss: 27.838\n",
      "Batch 2000, Loss: 28.039\n",
      "Batch 2100, Loss: 30.199\n",
      "Batch 2200, Loss: 29.267\n",
      "\n",
      "Val Loss: 48.051\n",
      "***************************************************\n",
      "\n",
      "Epoch: 12\n",
      "Batch 100, Loss: 31.610\n",
      "Batch 200, Loss: 30.411\n",
      "Batch 300, Loss: 29.656\n",
      "Batch 400, Loss: 26.695\n",
      "Batch 500, Loss: 30.735\n",
      "Batch 600, Loss: 26.714\n",
      "Batch 700, Loss: 27.903\n",
      "Batch 800, Loss: 26.392\n",
      "Batch 900, Loss: 27.215\n",
      "Batch 1000, Loss: 27.657\n",
      "Batch 1100, Loss: 29.212\n",
      "Batch 1200, Loss: 26.576\n",
      "Batch 1300, Loss: 31.843\n",
      "Batch 1400, Loss: 30.800\n",
      "Batch 1500, Loss: 28.803\n",
      "Batch 1600, Loss: 27.714\n",
      "Batch 1700, Loss: 28.563\n",
      "Batch 1800, Loss: 29.641\n",
      "Batch 1900, Loss: 28.598\n",
      "Batch 2000, Loss: 27.641\n",
      "Batch 2100, Loss: 29.984\n",
      "Batch 2200, Loss: 25.856\n",
      "\n",
      "Val Loss: 48.899\n",
      "***************************************************\n",
      "\n",
      "Epoch: 13\n",
      "Batch 100, Loss: 28.939\n",
      "Batch 200, Loss: 28.132\n",
      "Batch 300, Loss: 27.538\n",
      "Batch 400, Loss: 28.669\n",
      "Batch 500, Loss: 28.896\n",
      "Batch 600, Loss: 27.601\n",
      "Batch 700, Loss: 26.269\n",
      "Batch 800, Loss: 27.225\n",
      "Batch 900, Loss: 25.306\n",
      "Batch 1000, Loss: 27.947\n",
      "Batch 1100, Loss: 25.317\n",
      "Batch 1200, Loss: 27.086\n",
      "Batch 1300, Loss: 26.627\n",
      "Batch 1400, Loss: 26.243\n",
      "Batch 1500, Loss: 28.239\n",
      "Batch 1600, Loss: 25.103\n",
      "Batch 1700, Loss: 27.842\n",
      "Batch 1800, Loss: 26.867\n",
      "Batch 1900, Loss: 27.485\n",
      "Batch 2000, Loss: 26.832\n",
      "Batch 2100, Loss: 25.153\n",
      "Batch 2200, Loss: 26.008\n",
      "\n",
      "Val Loss: 49.353\n",
      "***************************************************\n",
      "\n",
      "Epoch: 14\n",
      "Batch 100, Loss: 28.308\n",
      "Batch 200, Loss: 26.304\n",
      "Batch 300, Loss: 23.489\n",
      "Batch 400, Loss: 25.823\n",
      "Batch 500, Loss: 26.517\n",
      "Batch 600, Loss: 24.879\n",
      "Batch 700, Loss: 26.942\n",
      "Batch 800, Loss: 26.170\n",
      "Batch 900, Loss: 23.927\n",
      "Batch 1000, Loss: 27.112\n",
      "Batch 1100, Loss: 27.766\n",
      "Batch 1200, Loss: 26.305\n",
      "Batch 1300, Loss: 28.554\n",
      "Batch 1400, Loss: 25.211\n",
      "Batch 1500, Loss: 24.727\n",
      "Batch 1600, Loss: 26.719\n",
      "Batch 1700, Loss: 26.853\n",
      "Batch 1800, Loss: 27.078\n",
      "Batch 1900, Loss: 26.186\n",
      "Batch 2000, Loss: 24.451\n",
      "Batch 2100, Loss: 25.920\n",
      "Batch 2200, Loss: 25.509\n",
      "\n",
      "Val Loss: 49.986\n",
      "***************************************************\n",
      "\n",
      "Epoch: 15\n",
      "Batch 100, Loss: 26.102\n",
      "Batch 200, Loss: 26.669\n",
      "Batch 300, Loss: 25.879\n",
      "Batch 400, Loss: 23.280\n",
      "Batch 500, Loss: 26.851\n",
      "Batch 600, Loss: 25.258\n",
      "Batch 700, Loss: 23.337\n",
      "Batch 800, Loss: 22.196\n",
      "Batch 900, Loss: 26.898\n",
      "Batch 1000, Loss: 27.882\n",
      "Batch 1100, Loss: 26.511\n",
      "Batch 1200, Loss: 27.101\n",
      "Batch 1300, Loss: 24.157\n",
      "Batch 1400, Loss: 26.254\n",
      "Batch 1500, Loss: 26.860\n",
      "Batch 1600, Loss: 28.698\n",
      "Batch 1700, Loss: 24.278\n",
      "Batch 1800, Loss: 26.145\n",
      "Batch 1900, Loss: 25.734\n",
      "Batch 2000, Loss: 26.331\n",
      "Batch 2100, Loss: 25.293\n",
      "Batch 2200, Loss: 26.168\n",
      "\n",
      "Val Loss: 48.908\n",
      "***************************************************\n",
      "\n",
      "Epoch: 16\n",
      "Batch 100, Loss: 26.306\n",
      "Batch 200, Loss: 24.619\n",
      "Batch 300, Loss: 23.850\n",
      "Batch 400, Loss: 24.670\n",
      "Batch 500, Loss: 26.575\n",
      "Batch 600, Loss: 24.801\n",
      "Batch 700, Loss: 26.409\n",
      "Batch 800, Loss: 27.055\n",
      "Batch 900, Loss: 24.514\n",
      "Batch 1000, Loss: 25.307\n",
      "Batch 1100, Loss: 25.709\n",
      "Batch 1200, Loss: 23.791\n",
      "Batch 1300, Loss: 23.412\n",
      "Batch 1400, Loss: 24.878\n",
      "Batch 1500, Loss: 26.239\n",
      "Batch 1600, Loss: 25.145\n",
      "Batch 1700, Loss: 24.397\n",
      "Batch 1800, Loss: 24.985\n",
      "Batch 1900, Loss: 24.702\n",
      "Batch 2000, Loss: 25.922\n",
      "Batch 2100, Loss: 25.233\n",
      "Batch 2200, Loss: 23.587\n",
      "\n",
      "Val Loss: 52.474\n",
      "***************************************************\n",
      "\n",
      "Epoch: 17\n",
      "Batch 100, Loss: 24.643\n",
      "Batch 200, Loss: 25.157\n",
      "Batch 300, Loss: 25.927\n",
      "Batch 400, Loss: 25.718\n",
      "Batch 500, Loss: 25.093\n",
      "Batch 600, Loss: 25.681\n",
      "Batch 700, Loss: 23.952\n",
      "Batch 800, Loss: 24.431\n",
      "Batch 900, Loss: 24.276\n",
      "Batch 1000, Loss: 25.832\n",
      "Batch 1100, Loss: 23.142\n",
      "Batch 1200, Loss: 24.585\n",
      "Batch 1300, Loss: 25.119\n",
      "Batch 1400, Loss: 23.941\n",
      "Batch 1500, Loss: 24.715\n",
      "Batch 1600, Loss: 24.759\n",
      "Batch 1700, Loss: 24.722\n",
      "Batch 1800, Loss: 25.032\n",
      "Batch 1900, Loss: 26.062\n",
      "Batch 2000, Loss: 22.479\n",
      "Batch 2100, Loss: 22.545\n",
      "Batch 2200, Loss: 25.411\n",
      "\n",
      "Val Loss: 52.430\n",
      "***************************************************\n",
      "\n",
      "Epoch: 18\n",
      "Batch 100, Loss: 22.953\n",
      "Batch 200, Loss: 22.745\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()\n",
    "\n",
    "    #every 5 epochs plot the performance\n",
    "    with torch.no_grad():\n",
    "        predicted = model(X_train_tensor.to(device)).to('cpu')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "split_index = int(0.8*len(X))#80% train, 20% test\n",
    "X_train = X[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicted = model(X_train_tensor.to(device)).to('cpu')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "y_true = y_train_tensor.to('cpu')\n",
    "R = np.corrcoef(predicted.squeeze(), y_true.squeeze())[0,1]\n",
    "\n",
    "plt.plot(X_train.index, y_true,  label=f'Actual {feat}')\n",
    "plt.plot(X_train.index, predicted, label=f'Predicted {feat}')\n",
    "\n",
    "plt.title(f'Prediction using LSTM from 21/05/10 -- 21/05/14, Epochs: {num_epochs}')\n",
    "plt.annotate(f'R={R:.2f}', xy=(0.05, 0.1), xycoords='axes fraction', fontsize=12,fontweight='bold')\n",
    "plt.xlabel(' ')\n",
    "plt.ylabel(f'Polar Cap Potential [kV]')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'{feat}_lstm_dt.png', dpi=300)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(epochs, model, train_loader, test_loader, optimizer, loss_function, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(True)  # Set the model to train mode\n",
    "        print(f'Epoch: {epoch + 1}')\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        for batch_index, batch in enumerate(train_loader):\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            \n",
    "            output = model(x_batch)\n",
    "            loss = loss_function(output, y_batch)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_index % 100 == 99:  # print every 100 batches\n",
    "                avg_loss_across_batches = running_loss / 100\n",
    "                print('Training Batch {0}, Loss: {1:.3f}'.format(batch_index+1, avg_loss_across_batches))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Validation loop\n",
    "        model.train(False)  # Set the model to evaluation mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_index, batch in enumerate(test_loader):\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(x_batch)\n",
    "                loss = loss_function(output, y_batch)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        val_losses.append(running_loss / len(test_loader))\n",
    "        \n",
    "        print('Validation Loss: {0:.3f}'.format(val_losses[-1]))\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "#earning_rate = 0.001\n",
    "#num_epochs = 10\n",
    "#loss_function = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#train_losses, val_losses = train_and_validate(num_epochs, model, train_loader, test_loader, optimizer, loss_function, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "server_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
