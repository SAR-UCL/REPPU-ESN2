{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xarray as xr\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>pot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-10 00:00:00</td>\n",
       "      <td>5809.586914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-10 00:01:00</td>\n",
       "      <td>5587.290039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-10 00:02:00</td>\n",
       "      <td>5441.645508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-10 00:03:00</td>\n",
       "      <td>5337.943359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-10 00:04:00</td>\n",
       "      <td>5247.345215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228955</th>\n",
       "      <td>2022-08-19 23:55:00</td>\n",
       "      <td>-9138.757812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228956</th>\n",
       "      <td>2022-08-19 23:56:00</td>\n",
       "      <td>-8673.632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228957</th>\n",
       "      <td>2022-08-19 23:57:00</td>\n",
       "      <td>-8447.510742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228958</th>\n",
       "      <td>2022-08-19 23:58:00</td>\n",
       "      <td>-8838.247070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228959</th>\n",
       "      <td>2022-08-19 23:59:00</td>\n",
       "      <td>-9497.301758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228960 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dt          pot\n",
       "0      2021-05-10 00:00:00  5809.586914\n",
       "1      2021-05-10 00:01:00  5587.290039\n",
       "2      2021-05-10 00:02:00  5441.645508\n",
       "3      2021-05-10 00:03:00  5337.943359\n",
       "4      2021-05-10 00:04:00  5247.345215\n",
       "...                    ...          ...\n",
       "228955 2022-08-19 23:55:00 -9138.757812\n",
       "228956 2022-08-19 23:56:00 -8673.632812\n",
       "228957 2022-08-19 23:57:00 -8447.510742\n",
       "228958 2022-08-19 23:58:00 -8838.247070\n",
       "228959 2022-08-19 23:59:00 -9497.301758\n",
       "\n",
       "[228960 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_reppu_data():\n",
    "    #path = r'/home/ryuho/Documents/reddy/research/SMRAI/Data/REPPU/200/pbig5min.dat' #Ubuntu\n",
    "    path = r'/home/sachin/Documents/NIPR/Research/Data/REPPU/pbig1min.dat' #Server\n",
    "\n",
    "    #read the REPPU data\n",
    "    with open (path) as f:\n",
    "        rectype = np.dtype(np.float32)\n",
    "        reppu_data = np.fromfile(f, rectype) #size = 109,900,800\n",
    "\n",
    "    reppu_data = reppu_data.reshape(-1,30,80)\n",
    "    reppu_data = reppu_data.mean(axis=1).mean(axis=1) #integrate over the 30x80 grid\n",
    "\n",
    "    #load MHD dates to match with REPPU data\n",
    "    mhd_data = pd.read_csv('mhd_dates.csv')\n",
    "    expanded_dt = pd.concat([pd.Series(pd.date_range(start, end)) \n",
    "        for start, end in zip(mhd_data['start'], mhd_data['end'])])\n",
    "    \n",
    "    time = np.arange(1440)\n",
    "    dt = []\n",
    "    for day in expanded_dt:\n",
    "        for t in time:\n",
    "            dt.append(day + pd.Timedelta(minutes=t*1))\n",
    "    dt = np.array(dt) #convert from list to numpy array\n",
    "    df = pd.DataFrame(reppu_data, index=dt)\n",
    "    df = df.rename(columns={0:'pot'})\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index':'dt'}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "reppu_df = process_reppu_data()\n",
    "reppu_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21744/369454973.py:6: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  omni_df = omni_df.interpolate()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>pot</th>\n",
       "      <th>BY_GSE</th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>flow_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>tilt_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>-8.954549</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>351.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.352885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-01 00:01:00</td>\n",
       "      <td>-8.217284</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>350.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.352224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-01 00:02:00</td>\n",
       "      <td>-7.373014</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>349.8</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.351564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-01 00:03:00</td>\n",
       "      <td>-6.258748</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>349.2</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.350904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-01 00:04:00</td>\n",
       "      <td>-5.868861</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>348.6</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.350244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022-07-30 23:55:00</td>\n",
       "      <td>-6.550199</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.57</td>\n",
       "      <td>0.275340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022-07-30 23:56:00</td>\n",
       "      <td>-6.405646</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.57</td>\n",
       "      <td>0.275340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022-07-30 23:57:00</td>\n",
       "      <td>-6.196533</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.57</td>\n",
       "      <td>0.275340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022-07-30 23:58:00</td>\n",
       "      <td>-6.239224</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.57</td>\n",
       "      <td>0.275340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022-07-30 23:59:00</td>\n",
       "      <td>-6.452317</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.57</td>\n",
       "      <td>0.275340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dt       pot  BY_GSE  BZ_GSE  flow_speed  \\\n",
       "0     2022-07-01 00:00:00 -8.954549   -1.51  -0.090       351.0   \n",
       "1     2022-07-01 00:01:00 -8.217284   -1.50  -0.114       350.4   \n",
       "2     2022-07-01 00:02:00 -7.373014   -1.49  -0.138       349.8   \n",
       "3     2022-07-01 00:03:00 -6.258748   -1.48  -0.162       349.2   \n",
       "4     2022-07-01 00:04:00 -5.868861   -1.47  -0.186       348.6   \n",
       "...                   ...       ...     ...     ...         ...   \n",
       "43195 2022-07-30 23:55:00 -6.550199   -6.48  -1.000       345.0   \n",
       "43196 2022-07-30 23:56:00 -6.405646   -6.48  -1.000       345.0   \n",
       "43197 2022-07-30 23:57:00 -6.196533   -6.48  -1.000       345.0   \n",
       "43198 2022-07-30 23:58:00 -6.239224   -6.48  -1.000       345.0   \n",
       "43199 2022-07-30 23:59:00 -6.452317   -6.48  -1.000       345.0   \n",
       "\n",
       "       proton_density  tilt_angle  \n",
       "0                4.50    0.352885  \n",
       "1                4.46    0.352224  \n",
       "2                4.42    0.351564  \n",
       "3                4.38    0.350904  \n",
       "4                4.34    0.350244  \n",
       "...               ...         ...  \n",
       "43195           11.57    0.275340  \n",
       "43196           11.57    0.275340  \n",
       "43197           11.57    0.275340  \n",
       "43198           11.57    0.275340  \n",
       "43199           11.57    0.275340  \n",
       "\n",
       "[43200 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_omni_and_merge(reppu_df):\n",
    "    reppu_df = reppu_df.copy()\n",
    "    \n",
    "    omni_df = pd.read_csv('omni_mhd_5min.csv')\n",
    "    #omni_df = pd.read_csv('omni_add-feats_mhd_5min.csv')\n",
    "    omni_df = omni_df.interpolate()\n",
    "    #omni_df = omni_df.ffill().bfill() #interpolate missing values\n",
    "    #omni_df = omni_df.dropna() \n",
    "    omni_df['dt'] = pd.to_datetime(omni_df['dt'])\n",
    "\n",
    "    #merge the REPPU and OMNI data\n",
    "    df = pd.merge(reppu_df, omni_df, on='dt', how='outer')\n",
    "    #df = df[(df['dt'] >= '2021-12-01') & (df['dt'] <= '2022-01-24')]\n",
    "    #df = df[(df['dt'] >= '2021-12-01') & (df['dt'] <= '2021-12-02')]\n",
    "    #df = df[(df['dt'] >= '2021-05-10') & (df['dt'] <= '2021-05-15')] #Kp 7 storm\n",
    "    df = df[(df['dt'] >= '2022-07-01 00:00:00') & (df['dt'] <= '2022-07-30 23:59:00')] #7 window\n",
    "    df['pot'] = df['pot'] * 1e-3\n",
    "    #interpolate\n",
    "    df = df.interpolate()\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "df = process_omni_and_merge(reppu_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pot</th>\n",
       "      <th>BY_GSE</th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>flow_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>tilt_angle</th>\n",
       "      <th>BY_GSE(t-1)</th>\n",
       "      <th>BZ_GSE(t-1)</th>\n",
       "      <th>flow_speed(t-1)</th>\n",
       "      <th>proton_density(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>BY_GSE(t-5)</th>\n",
       "      <th>BZ_GSE(t-5)</th>\n",
       "      <th>flow_speed(t-5)</th>\n",
       "      <th>proton_density(t-5)</th>\n",
       "      <th>tilt_angle(t-5)</th>\n",
       "      <th>BY_GSE(t-6)</th>\n",
       "      <th>BZ_GSE(t-6)</th>\n",
       "      <th>flow_speed(t-6)</th>\n",
       "      <th>proton_density(t-6)</th>\n",
       "      <th>tilt_angle(t-6)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-01 00:06:00</th>\n",
       "      <td>-4.732895</td>\n",
       "      <td>-1.502</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>347.8</td>\n",
       "      <td>4.298</td>\n",
       "      <td>0.348929</td>\n",
       "      <td>-1.460</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>348.0</td>\n",
       "      <td>4.300</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.500</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>350.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.352224</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>351.0</td>\n",
       "      <td>4.500</td>\n",
       "      <td>0.352885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01 00:07:00</th>\n",
       "      <td>-4.319199</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>347.6</td>\n",
       "      <td>4.296</td>\n",
       "      <td>0.348274</td>\n",
       "      <td>-1.502</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>347.8</td>\n",
       "      <td>4.298</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>349.8</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.351564</td>\n",
       "      <td>-1.500</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>350.4</td>\n",
       "      <td>4.460</td>\n",
       "      <td>0.352224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01 00:08:00</th>\n",
       "      <td>-4.223934</td>\n",
       "      <td>-1.586</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>347.4</td>\n",
       "      <td>4.294</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>347.6</td>\n",
       "      <td>4.296</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.480</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>349.2</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.350904</td>\n",
       "      <td>-1.490</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>349.8</td>\n",
       "      <td>4.420</td>\n",
       "      <td>0.351564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01 00:09:00</th>\n",
       "      <td>-4.593560</td>\n",
       "      <td>-1.628</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>347.2</td>\n",
       "      <td>4.292</td>\n",
       "      <td>0.346964</td>\n",
       "      <td>-1.586</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>347.4</td>\n",
       "      <td>4.294</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.470</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>348.6</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.350244</td>\n",
       "      <td>-1.480</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>349.2</td>\n",
       "      <td>4.380</td>\n",
       "      <td>0.350904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01 00:10:00</th>\n",
       "      <td>-4.804429</td>\n",
       "      <td>-1.670</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>347.0</td>\n",
       "      <td>4.290</td>\n",
       "      <td>0.346309</td>\n",
       "      <td>-1.628</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>347.2</td>\n",
       "      <td>4.292</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.460</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>348.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.349584</td>\n",
       "      <td>-1.470</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>348.6</td>\n",
       "      <td>4.340</td>\n",
       "      <td>0.350244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-30 23:55:00</th>\n",
       "      <td>-6.550199</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>0.275340</td>\n",
       "      <td>-6.256</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>343.6</td>\n",
       "      <td>11.520</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.360</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>338.0</td>\n",
       "      <td>11.32</td>\n",
       "      <td>0.278727</td>\n",
       "      <td>-5.338</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>337.8</td>\n",
       "      <td>11.286</td>\n",
       "      <td>0.279409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-30 23:56:00</th>\n",
       "      <td>-6.405646</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>0.275340</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.584</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>339.4</td>\n",
       "      <td>11.37</td>\n",
       "      <td>0.278050</td>\n",
       "      <td>-5.360</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>338.0</td>\n",
       "      <td>11.320</td>\n",
       "      <td>0.278727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-30 23:57:00</th>\n",
       "      <td>-6.196533</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>0.275340</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.808</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>340.8</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.277372</td>\n",
       "      <td>-5.584</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>339.4</td>\n",
       "      <td>11.370</td>\n",
       "      <td>0.278050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-30 23:58:00</th>\n",
       "      <td>-6.239224</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>0.275340</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.032</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>342.2</td>\n",
       "      <td>11.47</td>\n",
       "      <td>0.276695</td>\n",
       "      <td>-5.808</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>340.8</td>\n",
       "      <td>11.420</td>\n",
       "      <td>0.277372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-30 23:59:00</th>\n",
       "      <td>-6.452317</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>0.275340</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>11.570</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.256</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>343.6</td>\n",
       "      <td>11.52</td>\n",
       "      <td>0.276018</td>\n",
       "      <td>-6.032</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>342.2</td>\n",
       "      <td>11.470</td>\n",
       "      <td>0.276695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43194 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pot  BY_GSE  BZ_GSE  flow_speed  proton_density  \\\n",
       "dt                                                                          \n",
       "2022-07-01 00:06:00 -4.732895  -1.502  -0.218       347.8           4.298   \n",
       "2022-07-01 00:07:00 -4.319199  -1.544  -0.226       347.6           4.296   \n",
       "2022-07-01 00:08:00 -4.223934  -1.586  -0.234       347.4           4.294   \n",
       "2022-07-01 00:09:00 -4.593560  -1.628  -0.242       347.2           4.292   \n",
       "2022-07-01 00:10:00 -4.804429  -1.670  -0.250       347.0           4.290   \n",
       "...                       ...     ...     ...         ...             ...   \n",
       "2022-07-30 23:55:00 -6.550199  -6.480  -1.000       345.0          11.570   \n",
       "2022-07-30 23:56:00 -6.405646  -6.480  -1.000       345.0          11.570   \n",
       "2022-07-30 23:57:00 -6.196533  -6.480  -1.000       345.0          11.570   \n",
       "2022-07-30 23:58:00 -6.239224  -6.480  -1.000       345.0          11.570   \n",
       "2022-07-30 23:59:00 -6.452317  -6.480  -1.000       345.0          11.570   \n",
       "\n",
       "                     tilt_angle  BY_GSE(t-1)  BZ_GSE(t-1)  flow_speed(t-1)  \\\n",
       "dt                                                                           \n",
       "2022-07-01 00:06:00    0.348929       -1.460       -0.210            348.0   \n",
       "2022-07-01 00:07:00    0.348274       -1.502       -0.218            347.8   \n",
       "2022-07-01 00:08:00    0.347619       -1.544       -0.226            347.6   \n",
       "2022-07-01 00:09:00    0.346964       -1.586       -0.234            347.4   \n",
       "2022-07-01 00:10:00    0.346309       -1.628       -0.242            347.2   \n",
       "...                         ...          ...          ...              ...   \n",
       "2022-07-30 23:55:00    0.275340       -6.256       -0.886            343.6   \n",
       "2022-07-30 23:56:00    0.275340       -6.480       -1.000            345.0   \n",
       "2022-07-30 23:57:00    0.275340       -6.480       -1.000            345.0   \n",
       "2022-07-30 23:58:00    0.275340       -6.480       -1.000            345.0   \n",
       "2022-07-30 23:59:00    0.275340       -6.480       -1.000            345.0   \n",
       "\n",
       "                     proton_density(t-1)  ...  BY_GSE(t-5)  BZ_GSE(t-5)  \\\n",
       "dt                                        ...                             \n",
       "2022-07-01 00:06:00                4.300  ...       -1.500       -0.114   \n",
       "2022-07-01 00:07:00                4.298  ...       -1.490       -0.138   \n",
       "2022-07-01 00:08:00                4.296  ...       -1.480       -0.162   \n",
       "2022-07-01 00:09:00                4.294  ...       -1.470       -0.186   \n",
       "2022-07-01 00:10:00                4.292  ...       -1.460       -0.210   \n",
       "...                                  ...  ...          ...          ...   \n",
       "2022-07-30 23:55:00               11.520  ...       -5.360       -0.430   \n",
       "2022-07-30 23:56:00               11.570  ...       -5.584       -0.544   \n",
       "2022-07-30 23:57:00               11.570  ...       -5.808       -0.658   \n",
       "2022-07-30 23:58:00               11.570  ...       -6.032       -0.772   \n",
       "2022-07-30 23:59:00               11.570  ...       -6.256       -0.886   \n",
       "\n",
       "                     flow_speed(t-5)  proton_density(t-5)  tilt_angle(t-5)  \\\n",
       "dt                                                                           \n",
       "2022-07-01 00:06:00            350.4                 4.46         0.352224   \n",
       "2022-07-01 00:07:00            349.8                 4.42         0.351564   \n",
       "2022-07-01 00:08:00            349.2                 4.38         0.350904   \n",
       "2022-07-01 00:09:00            348.6                 4.34         0.350244   \n",
       "2022-07-01 00:10:00            348.0                 4.30         0.349584   \n",
       "...                              ...                  ...              ...   \n",
       "2022-07-30 23:55:00            338.0                11.32         0.278727   \n",
       "2022-07-30 23:56:00            339.4                11.37         0.278050   \n",
       "2022-07-30 23:57:00            340.8                11.42         0.277372   \n",
       "2022-07-30 23:58:00            342.2                11.47         0.276695   \n",
       "2022-07-30 23:59:00            343.6                11.52         0.276018   \n",
       "\n",
       "                     BY_GSE(t-6)  BZ_GSE(t-6)  flow_speed(t-6)  \\\n",
       "dt                                                               \n",
       "2022-07-01 00:06:00       -1.510       -0.090            351.0   \n",
       "2022-07-01 00:07:00       -1.500       -0.114            350.4   \n",
       "2022-07-01 00:08:00       -1.490       -0.138            349.8   \n",
       "2022-07-01 00:09:00       -1.480       -0.162            349.2   \n",
       "2022-07-01 00:10:00       -1.470       -0.186            348.6   \n",
       "...                          ...          ...              ...   \n",
       "2022-07-30 23:55:00       -5.338       -0.126            337.8   \n",
       "2022-07-30 23:56:00       -5.360       -0.430            338.0   \n",
       "2022-07-30 23:57:00       -5.584       -0.544            339.4   \n",
       "2022-07-30 23:58:00       -5.808       -0.658            340.8   \n",
       "2022-07-30 23:59:00       -6.032       -0.772            342.2   \n",
       "\n",
       "                     proton_density(t-6)  tilt_angle(t-6)  \n",
       "dt                                                         \n",
       "2022-07-01 00:06:00                4.500         0.352885  \n",
       "2022-07-01 00:07:00                4.460         0.352224  \n",
       "2022-07-01 00:08:00                4.420         0.351564  \n",
       "2022-07-01 00:09:00                4.380         0.350904  \n",
       "2022-07-01 00:10:00                4.340         0.350244  \n",
       "...                                  ...              ...  \n",
       "2022-07-30 23:55:00               11.286         0.279409  \n",
       "2022-07-30 23:56:00               11.320         0.278727  \n",
       "2022-07-30 23:57:00               11.370         0.278050  \n",
       "2022-07-30 23:58:00               11.420         0.277372  \n",
       "2022-07-30 23:59:00               11.470         0.276695  \n",
       "\n",
       "[43194 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_feat_df(df, lookback, var):\n",
    "    df = df.copy()\n",
    "    #df = df[['dt',var]]\n",
    "\n",
    "    df.set_index('dt', inplace=True)\n",
    "    \n",
    "    for i in range(1, lookback+1):\n",
    "        #df[f'{var}(t-{i})'] = df[var].shift(i)\n",
    "        df[f'BY_GSE(t-{i})'] = df['BY_GSE'].shift(i)\n",
    "        df[f'BZ_GSE(t-{i})'] = df['BZ_GSE'].shift(i)\n",
    "        df[f'flow_speed(t-{i})'] = df['flow_speed'].shift(i)\n",
    "        df[f'proton_density(t-{i})'] = df['proton_density'].shift(i)\n",
    "        df[f'tilt_angle(t-{i})'] = df['tilt_angle'].shift(i)\n",
    "        \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "feat = 'pot'\n",
    "df = single_feat_df(df, 6, feat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_split_tensor(df):\n",
    "\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df.iloc[:, 0]\n",
    "\n",
    "    #scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    split_train = int(0.8*len(X))#80% train, 20% test\n",
    "    split_val_test = int(0.5*len(X[split_train:]))#10% val, 10% test\n",
    "\n",
    "    #split the data\n",
    "    X_train = X[:split_train]\n",
    "    X_val = X[split_train:split_train+split_val_test]\n",
    "    X_test = X[split_train+split_val_test:]\n",
    "\n",
    "    y_train = y[:split_train]\n",
    "    y_val = y[split_train:split_train+split_val_test]\n",
    "    y_test = y[split_train+split_val_test:]\n",
    "\n",
    "\n",
    "    #add exta dim for torch reqs\n",
    "    X_train = X_train.reshape(-1, X.shape[1], 1)\n",
    "    X_val = X_val.reshape(-1, X.shape[1], 1)\n",
    "    X_test = X_test.reshape(-1, X.shape[1], 1)\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    y_val = y_val.values.reshape(-1, 1)\n",
    "    y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "    #convert to tensor\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device) #convert to tensor and move to GPU\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    return X_train_tensor, X_val_tensor, X_test_tensor, y_train_tensor, y_val_tensor, y_test_tensor\n",
    "\n",
    "X_train_tensor, X_val_tensor, X_test_tensor, y_train_tensor, y_val_tensor, y_test_tensor = scale_split_tensor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([34555, 35, 1]),\n",
       " torch.Size([4319, 35, 1]),\n",
       " torch.Size([4320, 35, 1]),\n",
       " torch.Size([34555, 1]),\n",
       " torch.Size([4319, 1]),\n",
       " torch.Size([4320, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape, X_val_tensor.shape, X_test_tensor.shape, y_train_tensor.shape, y_val_tensor.shape, y_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 16 #bigger batch size = faster training\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 35, 1]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(1, 32, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = LSTM(1, 32, 2)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = np.inf\n",
    "wait = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 35.945, Val Loss: 69.085\n",
      "Epoch: 2, Train Loss: 32.892, Val Loss: 70.470\n",
      "Epoch: 3, Train Loss: 31.352, Val Loss: 70.499\n",
      "Epoch: 4, Train Loss: 31.296, Val Loss: 72.936\n",
      "Epoch: 5, Train Loss: 28.055, Val Loss: 84.569\n",
      "Epoch: 6, Train Loss: 26.278, Val Loss: 96.702\n",
      "Epoch: 7, Train Loss: 24.492, Val Loss: 98.663\n",
      "Epoch: 8, Train Loss: 23.066, Val Loss: 99.283\n",
      "Epoch: 9, Train Loss: 21.904, Val Loss: 94.463\n",
      "Epoch: 10, Train Loss: 21.360, Val Loss: 98.294\n",
      "Epoch: 11, Train Loss: 20.727, Val Loss: 110.443\n",
      "Epoch: 12, Train Loss: 18.222, Val Loss: 110.614\n",
      "Epoch: 13, Train Loss: 17.670, Val Loss: 104.558\n",
      "Epoch: 14, Train Loss: 16.168, Val Loss: 103.653\n",
      "Epoch: 15, Train Loss: 15.402, Val Loss: 116.360\n",
      "Epoch: 16, Train Loss: 13.912, Val Loss: 103.259\n",
      "Epoch: 17, Train Loss: 14.307, Val Loss: 95.355\n",
      "Epoch: 18, Train Loss: 13.550, Val Loss: 83.750\n",
      "Epoch: 19, Train Loss: 12.909, Val Loss: 102.636\n",
      "Epoch: 20, Train Loss: 11.804, Val Loss: 87.001\n",
      "Epoch: 21, Train Loss: 10.346, Val Loss: 89.948\n",
      "Epoch: 22, Train Loss: 10.142, Val Loss: 89.159\n",
      "Epoch: 23, Train Loss: 9.105, Val Loss: 88.360\n",
      "Epoch: 24, Train Loss: 8.900, Val Loss: 99.955\n",
      "Epoch: 25, Train Loss: 8.497, Val Loss: 83.865\n",
      "Epoch: 26, Train Loss: 7.274, Val Loss: 87.747\n",
      "Epoch: 27, Train Loss: 7.705, Val Loss: 87.694\n",
      "Epoch: 28, Train Loss: 6.936, Val Loss: 91.778\n",
      "Epoch: 29, Train Loss: 6.417, Val Loss: 84.780\n",
      "Epoch: 30, Train Loss: 6.307, Val Loss: 85.608\n",
      "Epoch: 31, Train Loss: 6.188, Val Loss: 84.385\n",
      "Epoch: 32, Train Loss: 6.324, Val Loss: 93.755\n",
      "Epoch: 33, Train Loss: 5.852, Val Loss: 85.872\n",
      "Epoch: 34, Train Loss: 5.383, Val Loss: 101.087\n",
      "Epoch: 35, Train Loss: 5.592, Val Loss: 85.937\n",
      "Epoch: 36, Train Loss: 5.383, Val Loss: 83.739\n",
      "Epoch: 37, Train Loss: 5.301, Val Loss: 92.267\n",
      "Epoch: 38, Train Loss: 4.886, Val Loss: 96.295\n",
      "Epoch: 39, Train Loss: 4.872, Val Loss: 86.030\n",
      "Epoch: 40, Train Loss: 4.725, Val Loss: 95.615\n",
      "Epoch: 41, Train Loss: 6.356, Val Loss: 88.414\n",
      "Epoch: 42, Train Loss: 8.346, Val Loss: 86.253\n",
      "Epoch: 43, Train Loss: 4.936, Val Loss: 91.756\n",
      "Epoch: 44, Train Loss: 19.469, Val Loss: 70.877\n",
      "Epoch: 45, Train Loss: 11.166, Val Loss: 78.462\n",
      "Epoch: 46, Train Loss: 10.097, Val Loss: 81.500\n",
      "Epoch: 47, Train Loss: 8.015, Val Loss: 86.584\n",
      "Epoch: 48, Train Loss: 6.974, Val Loss: 84.572\n",
      "Epoch: 49, Train Loss: 6.452, Val Loss: 74.363\n",
      "Epoch: 50, Train Loss: 6.722, Val Loss: 77.849\n",
      "Epoch: 51, Train Loss: 6.504, Val Loss: 77.724\n",
      "Epoch: 52, Train Loss: 5.309, Val Loss: 83.632\n",
      "Epoch: 53, Train Loss: 4.957, Val Loss: 83.516\n",
      "Epoch: 54, Train Loss: 4.949, Val Loss: 90.370\n",
      "Epoch: 55, Train Loss: 4.943, Val Loss: 79.990\n",
      "Epoch: 56, Train Loss: 4.660, Val Loss: 81.221\n",
      "Epoch: 57, Train Loss: 4.916, Val Loss: 80.727\n",
      "Epoch: 58, Train Loss: 4.130, Val Loss: 85.038\n",
      "Epoch: 59, Train Loss: 4.228, Val Loss: 80.377\n",
      "Epoch: 60, Train Loss: 3.781, Val Loss: 83.867\n",
      "Epoch: 61, Train Loss: 4.543, Val Loss: 77.570\n",
      "Epoch: 62, Train Loss: 4.194, Val Loss: 80.157\n",
      "Epoch: 63, Train Loss: 3.889, Val Loss: 74.124\n",
      "Epoch: 64, Train Loss: 3.803, Val Loss: 85.418\n",
      "Epoch: 65, Train Loss: 3.882, Val Loss: 82.599\n",
      "Epoch: 66, Train Loss: 3.797, Val Loss: 79.905\n",
      "Epoch: 67, Train Loss: 4.057, Val Loss: 84.972\n",
      "Epoch: 68, Train Loss: 3.495, Val Loss: 81.244\n",
      "Epoch: 69, Train Loss: 3.890, Val Loss: 86.812\n",
      "Epoch: 70, Train Loss: 3.609, Val Loss: 82.174\n",
      "Epoch: 71, Train Loss: 3.398, Val Loss: 76.951\n",
      "Epoch: 72, Train Loss: 3.253, Val Loss: 86.241\n",
      "Epoch: 73, Train Loss: 3.000, Val Loss: 84.516\n",
      "Epoch: 74, Train Loss: 3.380, Val Loss: 78.879\n",
      "Epoch: 75, Train Loss: 3.316, Val Loss: 82.813\n",
      "Epoch: 76, Train Loss: 2.904, Val Loss: 84.513\n",
      "Epoch: 77, Train Loss: 2.805, Val Loss: 81.898\n",
      "Epoch: 78, Train Loss: 2.736, Val Loss: 73.917\n",
      "Epoch: 79, Train Loss: 3.119, Val Loss: 72.810\n",
      "Epoch: 80, Train Loss: 2.985, Val Loss: 79.459\n",
      "Epoch: 81, Train Loss: 3.579, Val Loss: 79.618\n",
      "Epoch: 82, Train Loss: 2.510, Val Loss: 74.227\n",
      "Epoch: 83, Train Loss: 2.787, Val Loss: 83.029\n",
      "Epoch: 84, Train Loss: 2.856, Val Loss: 79.929\n",
      "Epoch: 85, Train Loss: 2.344, Val Loss: 76.228\n",
      "Epoch: 86, Train Loss: 2.574, Val Loss: 77.177\n",
      "Epoch: 87, Train Loss: 3.343, Val Loss: 79.084\n",
      "Epoch: 88, Train Loss: 2.855, Val Loss: 77.296\n",
      "Epoch: 89, Train Loss: 2.538, Val Loss: 78.522\n",
      "Epoch: 90, Train Loss: 2.391, Val Loss: 82.179\n",
      "Epoch: 91, Train Loss: 2.493, Val Loss: 77.426\n",
      "Epoch: 92, Train Loss: 3.297, Val Loss: 75.823\n",
      "Epoch: 93, Train Loss: 2.109, Val Loss: 78.160\n",
      "Epoch: 94, Train Loss: 2.696, Val Loss: 78.193\n",
      "Epoch: 95, Train Loss: 2.672, Val Loss: 75.536\n",
      "Epoch: 96, Train Loss: 2.776, Val Loss: 83.864\n",
      "Epoch: 97, Train Loss: 2.117, Val Loss: 82.280\n",
      "Epoch: 98, Train Loss: 2.742, Val Loss: 82.049\n",
      "Epoch: 99, Train Loss: 2.314, Val Loss: 84.090\n",
      "Epoch: 100, Train Loss: 2.210, Val Loss: 73.677\n",
      "Epoch: 101, Train Loss: 2.676, Val Loss: 77.573\n",
      "Epoch: 102, Train Loss: 2.051, Val Loss: 77.700\n",
      "Epoch: 103, Train Loss: 2.169, Val Loss: 74.245\n",
      "Epoch: 104, Train Loss: 3.246, Val Loss: 78.855\n",
      "Epoch: 105, Train Loss: 2.285, Val Loss: 81.844\n",
      "Epoch: 106, Train Loss: 2.356, Val Loss: 79.069\n",
      "Epoch: 107, Train Loss: 2.268, Val Loss: 72.277\n",
      "Epoch: 108, Train Loss: 1.941, Val Loss: 74.159\n",
      "Epoch: 109, Train Loss: 2.169, Val Loss: 80.614\n",
      "Epoch: 110, Train Loss: 2.128, Val Loss: 76.167\n",
      "Epoch: 111, Train Loss: 1.916, Val Loss: 74.666\n",
      "Epoch: 112, Train Loss: 2.395, Val Loss: 77.830\n",
      "Epoch: 113, Train Loss: 1.895, Val Loss: 86.648\n",
      "Epoch: 114, Train Loss: 2.405, Val Loss: 78.385\n",
      "Epoch: 115, Train Loss: 2.152, Val Loss: 79.507\n",
      "Epoch: 116, Train Loss: 2.079, Val Loss: 82.119\n",
      "Epoch: 117, Train Loss: 2.123, Val Loss: 81.295\n",
      "Epoch: 118, Train Loss: 2.052, Val Loss: 87.249\n",
      "Epoch: 119, Train Loss: 1.756, Val Loss: 81.190\n",
      "Epoch: 120, Train Loss: 1.928, Val Loss: 83.211\n",
      "Epoch: 121, Train Loss: 2.210, Val Loss: 77.414\n",
      "Epoch: 122, Train Loss: 1.811, Val Loss: 80.952\n",
      "Epoch: 123, Train Loss: 2.036, Val Loss: 79.007\n",
      "Epoch: 124, Train Loss: 1.715, Val Loss: 79.616\n",
      "Epoch: 125, Train Loss: 2.311, Val Loss: 82.112\n",
      "Epoch: 126, Train Loss: 1.700, Val Loss: 81.156\n",
      "Epoch: 127, Train Loss: 2.075, Val Loss: 79.949\n",
      "Epoch: 128, Train Loss: 1.570, Val Loss: 80.378\n",
      "Epoch: 129, Train Loss: 1.861, Val Loss: 81.254\n",
      "Epoch: 130, Train Loss: 2.544, Val Loss: 82.142\n",
      "Epoch: 131, Train Loss: 1.861, Val Loss: 79.590\n",
      "Epoch: 132, Train Loss: 1.701, Val Loss: 77.965\n",
      "Epoch: 133, Train Loss: 1.786, Val Loss: 80.066\n",
      "Epoch: 134, Train Loss: 1.948, Val Loss: 80.844\n",
      "Epoch: 135, Train Loss: 1.765, Val Loss: 79.438\n",
      "Epoch: 136, Train Loss: 1.730, Val Loss: 76.805\n",
      "Epoch: 137, Train Loss: 1.802, Val Loss: 78.390\n",
      "Epoch: 138, Train Loss: 2.631, Val Loss: 79.700\n",
      "Epoch: 139, Train Loss: 2.129, Val Loss: 86.488\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "start_time = dt.datetime.now()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device) #move to GPU\n",
    "        \n",
    "        output = model(x_batch) #forward pass\n",
    "        loss = loss_function(output, y_batch) #calculate loss\n",
    "        running_loss += loss.item() #accumulate loss\n",
    "        \n",
    "        optimizer.zero_grad() #zero gradients\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer.step() #update weights\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad(): #val has no gradients because we are not training\n",
    "        for batch_index, batch in enumerate(val_loader):\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            \n",
    "            output = model(x_batch) \n",
    "            loss = loss_function(output, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1}, Train Loss: {avg_train_loss:.3f}, Val Loss: {avg_val_loss:.3f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        wait = 0\n",
    "        #torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Validation loss did not improve for {patience} epochs. Stopping training.\")\n",
    "            end_time = dt.datetime.now()\n",
    "            diff = end_time - start_time\n",
    "            print(f'Training Time: {diff}')\n",
    "            break\n",
    "\n",
    "#best_model = model\n",
    "#best_model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss = 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        output = model(x_batch)\n",
    "        loss = loss_function(output, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f'Test Loss: {avg_test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "split_index = int(0.8*len(X))#80% train, 20% test\n",
    "X_train = X[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicted = model(X_train_tensor.to(device)).to('cpu')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "y_true = y_train_tensor.to('cpu')\n",
    "R = np.corrcoef(predicted.squeeze(), y_true.squeeze())[0,1]\n",
    "\n",
    "plt.plot(X_train.index, y_true,  label=f'Actual {feat}')\n",
    "plt.plot(X_train.index, predicted, label=f'Predicted {feat}')\n",
    "\n",
    "plt.title(f'Prediction using LSTM from 21/05/10 -- 21/05/14, Epochs: {num_epochs}')\n",
    "plt.annotate(f'R={R:.2f}', xy=(0.05, 0.1), xycoords='axes fraction', fontsize=12,fontweight='bold')\n",
    "plt.xlabel(' ')\n",
    "plt.ylabel(f'Polar Cap Potential [kV]')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'{feat}_lstm_dt.png', dpi=300)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "server_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
